<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="viewport" content="width=800">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    .hp-photo{ width:240px; height:240px; border-radius:240px; -webkit-border-radius:240px; -moz-border-radius:240px; }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 24px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
    </style>

    <title>Xiaoyang Lyu</title>
    <!--<link rel="stylesheet" type="text/css" href="/imgs/css" >-->
    <link rel="icon" type="image/png" href="./images/zju.png">
</head>

<body>
<table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
<tbody>
<tr>
<td>


    <!--SECTION 1 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td width="68%" valign="middle">
                <p align="center"><name>Xiaoyang Lyu (吕晓阳)</name></p>
                    I am a Master student (Sep. 2019 - Mar. 2022) in the <a href="http://www.cse.zju.edu.cn/english/">College of Control Science and Engineering</a>
                    at <a href="http://www.zju.edu.cn/english/">Zhejiang University</a>,
                    supervised by <a href="https://scholar.google.com/citations?hl=en&user=qYcgBbEAAAAJ&view_op=list_works&sortby=pubdate"> Prof. Yong Liu</a>.
                    Prior to ZJU, I obtained a B.Eng from <a href="http://en.hit.edu.cn/"> Harbin Institute Of Technology </a> and majored in robotics in the 
                    <a href="http://robot.hit.edu.cn/"> State Key Laboratory of Robotics and System</a>.

                    </br></br>
                    I was a research intern (July. 2019 - Sep. 2019) at <a href="https://www.megvii.com/megvii_research">Megvii Research Center</a> of <a href="https://www.megvii.com">Megvii</a> (Beijing, China).
                    And now I am a research intern (Nov. 2020 until now) at <a href="https://www.noahlab.com.hk/#/home">Noah's Ark Lab</a> of <a href="https://www.huawei.com/en/">Huawei</a> (Beijing, China).
                    In my undergraduate study, I was an team member of computer vision group in <a href="https://baike.baidu.com/item/哈尔滨工业大学竞技机器人队">
                    Harbin Institute of Technology Competition Robotics Team (HITCRT)</a>, named I Hiter (Harbin, China).

                    </br></br>
                    <!-- <strong><font color="red">Looking for a 2022 PhD position in computer vision / robotics perception! Welcome to contact me! </font></strong> -->

	            </br>
                </p><p align="center">
                    <a href="mailto:shawlyu[-at-]zju.edu.cn">Email</a> /
                    <!-- <a href="https://scholar.google.com/citations?hl=en&user=VqUAqz8AAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> &nbsp;/&nbsp;
                    -->
                    <a href="https://github.com/shawlyu"> Github </a>
                </p>
              </td>
			  <td align="right"> <img class="hp-photo" src="./images/lxy.jpg" style="width: 150; height: 225;"></td></tr>
            </tbody>
          </table>

    <!--SECTION 2 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
          <td>
          <heading>Research</heading>
           <p align="justify">I'm interested in computer vision and robotics. Currently I'm working on 3D scene reconstruction, which
               includes depth estimation, depth completion, SLAM. I hope to combine the advantages of deep learning and traditional 
               feature-based methods to build a robust and high-percision vision SLAM system. My research goal is to help the robot to
               percept the real world in human way.
           <!--</br></br>-->
		   <!--<span class="highlight"><strong>Internship Position: </strong> If you're interested in ...</span> -->
		   </p>
		   </td></tr>
       </tbody>
    </table>


    <!--SECTION 3 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading>Publications</heading>
          </td>
          </tr></tbody>
    </table>

    <!--SECTION 4 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody><tr>

        <td width="20%"><img src="./images/AAAI21/hr_depth.gif" alt="PontTuset" width="250" height="130" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="https://aaai.org/Conferences/AAAI-21/">
	            <papertitle>HR-Depth : High Resolution Self-Supervised Monocular Depth Estimation</papertitle></a>
                <br><strong>Xiaoyang Lyu</strong>, Liang Liu, Mengmeng Wang, Xin Kong, etc.
                <br>
                <em>The 35th AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, 2021. Virtual.
                <br>
                    <a href="https://arxiv.org/abs/2012.07356">arXiv</a> /
                    <a href="https://github.com/shawLyu/HR-Depth">code</a>
<!--                <a href="https://www.youtube.com/watch?v=H_uf-KEFA9s">presentation</a>-->

                </p><p></p>
			    <p align="justify" style="font-size:13px">Based on theoretical and empirical evidence, we present HR-Depth, for
                    high-resolution self-supervised monocular depth estimation.</p>
            </td>
        </tr>

        <td width="20%"><img src="./images/AAAI21/FCFR_pipeline.png" alt="PontTuset" width="250" height="130" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="https://aaai.org/Conferences/AAAI-21/">
	            <papertitle>FCFR-Net: Frature Fusion based Coarse-to-Fine Residual Learning for Depth Completion</papertitle></a>
                <br>Lina Liu, Xibin Song, <strong>Xiaoyang Lyu</strong>, Junwei Diao, etc.
                <br>
                <em>The 35th AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, 2021. Virtual.
                <br>
                    <a href="https://arxiv.org/abs/2012.08270">arXiv</a> /
                    code
                    <!-- <a href="https://arxiv.org/abs/2012.07356">arXiv</a> /
                    <a href="https://github.com/shawLyu/HR-Depth">code</a> -->
<!--                <a href="https://www.youtube.com/watch?v=H_uf-KEFA9s">presentation</a>-->

                </p><p></p>
                <p align="justify" style="font-size:13px">We propose a novel end-to-end residual learning framework, 
                    which formulates the depth completion as a tow-stage learning task. </p>
            </td>
        </tr>
		<tbody>
    </table>

    <!-- SECTION 5 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading>Competitions</heading>
          </td>
          </tr></tbody>
    </table>

    <!--SECTION 6 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
            <td width="20%"><img src="./images/ICRA18/robots.jpg" alt="PontTuset" width="250" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="https://www.robomaster.com/en-US/resource/pages/announcement/728">
	            <papertitle>ICRA 2018 DJI RoboMaster AI Challenge</papertitle></a>
                <br><a href="./images/ICRA18/team.jpg">Team: I Hiter</a>. Xingguang Zhong, Xin Kong, <strong>Xiaoyang Lyu</strong>, Le Qi, Hao Huang, Linrui Tian, Songwei Li
                <br>
                <em> IEEE International Conference on Robotics and Automation (<strong>ICRA</strong>)</em>, 2018. Brisbane, Australia.
                <br>
                <a href="./images/ICRA18/champion.jpg"><strong>Global Champion</strong> </a> /
                <a href="./images/ICRA18/ranking.jpg">Ranking: <strong>1st</strong>/21 </a>/
                <a href="./images/ICRA18/certificate.jpg">Certificate</a> /
                <a href="/images/ICRA18/ICRA18-DJI.mp4">Video</a> /
                <a href="./images/ICRA18/rules.pdf">Rules</a>
                </p><p></p>
			    <p align="justify" style="font-size:13px">Our team built two fully automatic robots, including <a href="./images/ICRA18/IHiter-tech.pdf">
                    machinery, circuit, control and algorithm</a>. I was responsible for visual servo, target detection, target localization and 
                    decision-making of robots.</p>
            </td>
        </tr>

        <tbody><tr>
            <td width="20%"><img src="./images/RM17/autofightback.gif" alt="PontTuset" width="250" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="https://www.robomaster.com/en-US/robo/history">
	            <papertitle>2017, 2018, 2019 RoboMaster Robotics Competition</papertitle></a>
                <br><a href="./images/RM17/team.jpg">Team: I Hiter</a>. Wei Chen, Xin Kong, <strong>Xiaoyang Lyu</strong>, etc. 
                <br>
                <em>China University Robot Competition (全国大学生机器人大赛)</em>, 2017, 2018, 2019. Shenzhen, China.
                <br>
                <a href="./images/RM17/first-prize.bmp"><strong>First Prize</strong> </a> /
                <a href="https://en.wikipedia.org/wiki/RoboMaster#Winners">Ranking: <strong>4th</strong>/200+ </a> in 2017, 2018, <a href="https://www.robomaster.com/en-US/resource/pages/announcement/1035"><strong>6th</strong>/200+ in 2019.</a>/
                <a href="./images/RM17/rm_lxy.png">Certificate</a> /
                <a href="https://www.bilibili.com/video/av27846163/">Highlights</a>
                </p><p></p>
			    <p align="justify" style="font-size:13px">Our team built more than <a href="https://www.bilibili.com/video/av23489177/">10 complex automatic or semi-automatic robots</a> every year.
                    In 2017, I was mainly responsible for building and <a href="images/RM17/manipulator.jfif">manipulating</a> Engineering Robot. In 2018, I was responsible for 
                    <a href="./images/RM17/visual-servo.mp4">visual servo</a>, which involves computer vision and machine learning. In 2019, I became the leader of computer vision group and the
                    coach of our team.</p>
            </td>
        </tr>
    </table>

    <!-- SECTION 5 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading>Projects</heading>
          </td>
          </tr></tbody>
    </table>

    <!--SECTION 6 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

        <tbody><tr>
            <td width="20%"><img src="./images/ST18/strawberry.gif" alt="PontTuset" width="250" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <papertitle>Flowing Strawberry Picking Robot</papertitle>
                <br><strong>Xiaoyang Lyu</strong>, Le Qi, Linrui Tian, Songwei Li
                <br>
                <em> Undergraduate Mechanical Innovation Competition.
                <br>
                <strong>First Prize</strong> /
                <a href="./images/ST18/certificates.jpg">Certificate</a> 
                </p><p></p>
                <p align="justify" style="font-size:13px"> Our group build a strawberry picking robot, 
                    which can detect strawberries and pick them automatically. I responsible for designing 
                    a machine learning algorithm which can detect strawberry on embedded platform.</td>
        </tr>

    </table>
    <!--SECTION 8 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
          <td>
          <heading>Honors</heading>
          <p>Nov. 2019, Academic scholarship - Zhejiang University </p>
          <p>Jun. 2019, Outstanding Graduate - Harbin Institute of Technology </p>
          <p>Jun. 2019, Top 100 excellent graduation thesis - Harbin Institute of Technology</p>
          <p>Mar. 2019, First price of innovation scholarship of MIIT - Harbin Institute of Technology</p>
          <p>Jan. 2019, Top 10 College Student in Harbin Institute of Technology - Harbin Institute of Technology</p>
          <p>Mar. 2018, Outstanding student in Hei Longjiang Province - Harbin Institute of Technology</p>
          <p>Oct. 2017, SMC Scholarship - Harbin Institute of Technology</p>
          <p>Oct. 2016, National Scholarship - Harbin Institute of Technology</p>
		   </td></tr>
       </tbody>
    </table>

    <!--SECTION 8 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
          <td>
          <heading>About Me</heading>
              <p> <strong>Skills</strong>: Python / C / C ++ / Matlab, PyTorch / TensorFlow, Linux, ROS, OpenCV</p>
		   </td></tr>
       </tbody>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
            <td width="100%" align="middle">
            <p align="center" style="width: 25% ">
            <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=3LiPnVFG5d-0xCFz-Mksb8GtJ_xg3bHvDe_e6PIrMAQ"></script>
            </p></td>
        </tr>
        </tbody>
    </table>

    <!--SECTION 10 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
         <tbody><tr>
            <td><br>
		       <p align="right"><font size="2"> Last update: 2020.12.17. <a href="http://www.cs.berkeley.edu/~barron/">Thanks.</a></font></p>
            </td>
         </tr>
         </tbody>
     </table>


</td>
</tr>
</tbody>
</table>
</body>
</html>